# A/B Test Analysis â€” Control vs Variant Revenue Performance

## ğŸ“Œ Project Overview
This project analyzes an A/B test dataset from Kaggle:
[AB Test Data](https://www.kaggle.com/datasets/sergylog/ab-test-data)

**Goal**: Determine whether the variant group generated significantly different conversion rates or revenue compared to the control group.

---

## Dataset - Column
- **USER_ID**: Unique user identifier
- **VARIANT_NAME**: 'control' or 'variant'
- **REVENUE**: Revenue generated by the user (can be 0)

**Key facts:**
- 10,000 total records, ~50/50 split between groups.
- 98.5% of users have zero revenue.
- Highly skewed revenue distribution with extreme outliers.

---

## Methods
### 1. **Exploratory Data Analysis (EDA)**
- Checked data balance, missing values, and outliers.
- Visualized conversion and revenue distributions.

### 2. **Hypothesis Testing**
- **Conversion Rate**: Two-proportion Z-test (binary paid/not paid).
- **Revenue (paying users)**: Mannâ€“Whitney U test (non-parametric).

### 3. **Additional Statistics**
- Effect size for both tests (Cohenâ€™s h, Rank-biserial correlation).
- Bootstrap confidence intervals for revenue differences.
- Minimum Detectable Effect (MDE) & power analysis.

---

## Results
| Metric                 | Control | Variant | p-value | Significance |
| ---------------------- | ------- | ------- | ------- | ------------ |
| Conversion Rate        | 1.61%   | 1.43%   | 0.488   | âŒ No         |
| Revenue (paying users) | 2,96    | 2,17    | 0.079   | âŒ No         |

- Effect sizes indicate negligible to small differences.
- Bootstrap CI includes zero â†’ differences may be positive or negative.
- Power analysis shows **MDE â‰ˆ 0,78 pp change**, requiring ~16Ã— more data to detect small effects.

---

## Key Takeaways
- Revenue data is **heavily skewed**, making non-parametric tests more reliable.
- No statistical evidence that the variant performs differently from control in conversion rate or payer revenue.
- Small observed differences could be due to random chance and dataset is underpowered for small effect sizes.

---

## ğŸ“ Files in This Repo
- `AB_Test_Project.ipynb` â†’ Full analysis notebook
- `AB_Test_Project.pdf` â†’ Clean PDF version
- `AB_Test.pptx` â†’ Slide deck presentation

---

## ğŸ”— Links
- **Dataset**: [Kaggle AB Test Data](https://www.kaggle.com/datasets/sergylog/ab-test-data)
- **Tableau/GitHub Portfolio**: *[Update with correct A/B Test dashboard link]*

---

## Skills Demonstrated
- Hypothesis testing: Z-test, Mannâ€“Whitney
- Effect size interpretation
- Power analysis & MDE
- Bootstrap confidence intervals
- Data visualization & storytelling
